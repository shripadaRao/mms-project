{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_hSPbyxHkhv",
        "outputId": "98be6f75-28f8-4165-e43d-57bfca7d86ab"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/Datasets/mms/spectrograms.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckCXkFinIDTV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDz5rqE5MAlZ"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def crop_image(image_path, left, upper, right, lower, output_path):\n",
        "    with Image.open(image_path) as img:\n",
        "        cropped_img = img.crop((left, upper, right, lower))\n",
        "        cropped_img.save(output_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqK_0EsLWMz5"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def threshold_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    \n",
        "    # img = img.convert('L')\n",
        "    \n",
        "    img = img.point(lambda p: 255 if p > 165 else p)\n",
        "    img = img.point(lambda p: 110 if p < 130  else p)\n",
        "    \n",
        "    # Save the modified image\n",
        "    img.save(\"thresholded_image.jpg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnG60DPpYCCt"
      },
      "outputs": [],
      "source": [
        "def pre_process_img(source_filepath, dest_filepath):\n",
        "\n",
        "  #crop the image\n",
        "  left, upper, right, lower = 80, 60, 475, 425\n",
        "  with Image.open(source_filepath) as img:\n",
        "      cropped_img = img.crop((left, upper, right, lower))\n",
        "  \n",
        "  #make it greyscale\n",
        "  grey_img = cropped_img.convert('L')\n",
        "\n",
        "  #pixel transform\n",
        "  grey_img = grey_img.point(lambda p: 255 if p > 165 else p)\n",
        "  grey_img = grey_img.point(lambda p: 110 if p < 130  else p)\n",
        "  print(np.asarray(grey_img))\n",
        "  #save image\n",
        "  # grey_img.save(dest_filepath)\n",
        "  # print(np.asarray(grey_img).shape)\n",
        "  return np.asarray(grey_img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tj9FH5U8bPsI",
        "outputId": "15795bee-309a-4ab9-910f-9204f1ddbd18"
      },
      "outputs": [],
      "source": [
        "\n",
        "# pre_process_img('spectrograms/sawing/file1.png', 'file1.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVUjlWvNbfxM"
      },
      "outputs": [],
      "source": [
        "# pre_process_img('spectrograms/ambient/file1.png', 'spectrograms/transformed/ambient/file1.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt0GuRpmd34w"
      },
      "outputs": [],
      "source": [
        "# import multiprocessing as mp\n",
        "# import os\n",
        "\n",
        "# num_processes = mp.cpu_count()\n",
        "# pool = mp.Pool(num_processes)\n",
        "\n",
        "# out_dir = \"spectrograms/transformed/ambient/\"\n",
        "# in_dir = \"spectrograms/ambient/\"\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "\n",
        "#     if not os.path.exists(out_dir):\n",
        "#         os.makedirs(out_dir)\n",
        "\n",
        "#     files = os.listdir(in_dir)\n",
        "\n",
        "#     # Create a pool of processes\n",
        "#     num_processes = mp.cpu_count()\n",
        "#     pool = mp.Pool(num_processes)\n",
        "\n",
        "#     # Use the pool to process the files\n",
        "#     results = []\n",
        "#     for f in files:\n",
        "#         result = pool.apply_async(pre_process_img, args=(in_dir + f, out_dir + f))\n",
        "#         results.append(result)\n",
        "\n",
        "#     # Wait for all processes to complete\n",
        "#     for result in results:\n",
        "#         result.wait()\n",
        "\n",
        "#     # Close the pool to free up resources\n",
        "#     pool.close()\n",
        "#     pool.join()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCzCyc4YevZE",
        "outputId": "81f0f1ba-1505-47de-f79f-1b960087baf5"
      },
      "outputs": [],
      "source": [
        "# !zip -r \"transformed.zip\" \"spectrograms/transformed/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXh4oAoZUOhE",
        "outputId": "6521088a-715d-4830-cdff-0754cdc3feca"
      },
      "outputs": [],
      "source": [
        "#cnn with 2 layers\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Flatten, Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define the input shape\n",
        "# Define the input shape\n",
        "input_shape = (365, 395, 1)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add a convolutional layer with 16 filters and a 3x3 kernel size\n",
        "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "\n",
        "# Flatten the output of the convolutional layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add the output layer with 2 neurons for the 2 classes (sawing and not sawing)\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model with categorical cross-entropy loss and Adam optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Define the data generator\n",
        "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load the training data from the directory\n",
        "train_data = data_generator.flow_from_directory(\n",
        "    'spectrograms/transformed/',\n",
        "    target_size=(365, 395),\n",
        "    batch_size=256,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "# Train the model for 10 epochs\n",
        "model.fit(train_data, epochs=3, callbacks=[early_stop])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSFcyMw9ZbTI"
      },
      "outputs": [],
      "source": [
        "model.save('cnn_model_v1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2ZxOYyEZs5e",
        "outputId": "f73bcaaa-4282-42c1-8c56-493c3790b060"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import load_img\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the saved model from a file\n",
        "loaded_model = load_model('cnn_model_v1.h5')\n",
        "\n",
        "pre_process_img(\"spectrograms/sawing/file112.png\", \"test7.png\")\n",
        "\n",
        "\n",
        "# Load the image\n",
        "img = tf.keras.utils.load_img('test7.png', target_size=(365, 395))\n",
        "\n",
        "\n",
        "# Convert the image to a numpy array\n",
        "# x = image.img_to_array(img)\n",
        "x = np.asarray(img)\n",
        "print(x)\n",
        "print('*'*10)\n",
        "\n",
        "# Preprocess the image using the same method as the training data\n",
        "x = x / 255.\n",
        "\n",
        "# Reshape the input data to match the expected shape of the model\n",
        "x = np.expand_dims(x, axis=0)\n",
        "# print(\"x\", x.shape)\n",
        "\n",
        "# Make the prediction using the model\n",
        "preds = model.predict(x)\n",
        "\n",
        "# Print the predicted class\n",
        "print(preds.argmax())\n",
        "\n",
        "if preds.argmax() == 1:\n",
        "  print('sawing!!')\n",
        "else:\n",
        "  print('not sawing!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STjKJL9xrUZz"
      },
      "outputs": [],
      "source": [
        "def pre_process_img2(source_filepath):\n",
        "\n",
        "  #crop the image\n",
        "  left, upper, right, lower = 80, 60, 475, 425\n",
        "  with Image.open(source_filepath) as img:\n",
        "      cropped_img = img.crop((left, upper, right, lower))\n",
        "  \n",
        "  #make it greyscale\n",
        "  grey_img = cropped_img.convert('L')\n",
        "\n",
        "  #pixel transform\n",
        "  grey_img = grey_img.point(lambda p: 255 if p > 165 else p)\n",
        "  grey_img = grey_img.point(lambda p: 110 if p < 130  else p)\n",
        "\n",
        "  return np.asarray(grey_img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEs9PChygMOq",
        "outputId": "9a0176fe-717a-487d-9180-d636fd117164"
      },
      "outputs": [],
      "source": [
        "#libraries\n",
        "from keras.models import load_model\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "# from tensorflow.keras.utils import load_img\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def predict_spectrogram(filepath):\n",
        "  model = load_model('/content/drive/MyDrive/Datasets/mms/cnn_model_v1.hdf5')\n",
        "  img_data = pre_process_img2(filepath)\n",
        "  x = img_data / 255.\n",
        "\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  preds = model.predict(x)\n",
        "  return True if preds.argmax()==1 else False\n",
        "predict_spectrogram('/content/drive/MyDrive/Datasets/spectogramImgs/file1.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VWLVOCShv50",
        "outputId": "904b1bfc-298c-44e2-f50b-70e35cdc369c"
      },
      "outputs": [],
      "source": [
        "!pip show tensorflow\n",
        "!pip show keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRFa2D0daUGd",
        "outputId": "d6ac8cec-4082-49de-dbb8-39c44b50dbfd"
      },
      "outputs": [],
      "source": [
        "!pip show flatbuffers tensorboard "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvBamptAampr",
        "outputId": "a836a992-7e13-4aec-f052-8939a4a02492"
      },
      "outputs": [],
      "source": [
        "!pip show protobuf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9PoLObJavAb",
        "outputId": "64b8ee0b-904a-43dc-9266-8ef748e6947d"
      },
      "outputs": [],
      "source": [
        "!pip show Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgOYdX03ewQ7",
        "outputId": "7e67753c-0c63-4127-b25e-ba04d651da70"
      },
      "outputs": [],
      "source": [
        "!pip show numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz5hTe38uJrN",
        "outputId": "e9e742d0-5a50-4fe3-f291-79061aa21de3"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/Datasets/mms/spectrograms.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwF0facyupLi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('spectrograms/transformed-v3/sawing/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USUHRiOMPYDJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('spectrograms/transformed-v3/ambient/')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qMD17I0KQGbP"
      },
      "source": [
        "*************************************\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ml786CzWHaGD"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def pre_process_img_v3(source_filepath,f):\n",
        "\n",
        "    # crop the image\n",
        "    left, upper, right, lower = 170, 200, 350, 380\n",
        "    with Image.open(source_filepath) as img:\n",
        "        cropped_img = img.crop((left, upper, right, lower))\n",
        "\n",
        "    # make it greyscale\n",
        "    grey_img = cropped_img.convert('L')\n",
        "\n",
        "    # pixel transform\n",
        "    grey_img = grey_img.point(lambda p: 255 if p > 165 else p)\n",
        "    grey_img = grey_img.point(lambda p: 110 if p < 130 else p)\n",
        "\n",
        "    # convert to numpy array \n",
        "    np_img = np.asarray(grey_img)\n",
        "\n",
        "    # Image.fromarray(np_img.save('random-test.png'))\n",
        "    # img = Image.fromarray(np_img)\n",
        "    # img.save(f)\n",
        "\n",
        "    return np_img\n",
        "# pre_process_img_v3('/content/spectrograms/sawing/file1090.png', 'random112.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsCwnGXNW2sz",
        "outputId": "53d316a6-9d25-4f19-d93f-ccbc4f3bec17"
      },
      "outputs": [],
      "source": [
        "print(len(os.listdir('spectrograms/transformed-v3/ambient/')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L23N9k8I6OZ-"
      },
      "outputs": [],
      "source": [
        "\n",
        "import multiprocessing as mp\n",
        "import os\n",
        "\n",
        "num_processes = mp.cpu_count()\n",
        "pool = mp.Pool(num_processes)\n",
        "\n",
        "out_dir = \"spectrograms/transformed-v3/sawing/\"\n",
        "in_dir = \"spectrograms/sawing/\"\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    if not os.path.exists(out_dir):\n",
        "        os.makedirs(out_dir)\n",
        "\n",
        "    files = os.listdir(in_dir)\n",
        "\n",
        "    # Create a pool of processes\n",
        "    num_processes = mp.cpu_count()\n",
        "    pool = mp.Pool(num_processes)\n",
        "\n",
        "    # Use the pool to process the files\n",
        "    results = []\n",
        "    for f in files:\n",
        "        result = pool.apply_async(pre_process_img_v3, args=(in_dir + f, out_dir + f))\n",
        "        results.append(result)\n",
        "\n",
        "    # Wait for all processes to complete\n",
        "    for result in results:\n",
        "        result.wait()\n",
        "\n",
        "    # Close the pool to free up resources\n",
        "    pool.close()\n",
        "    pool.join()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qiMwkU6XHmX",
        "outputId": "28612024-3034-42a1-9639-402aad6d8b2b"
      },
      "outputs": [],
      "source": [
        "print(len(os.listdir('spectrograms/transformed-v3/sawing/')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vG-fF0Jfx2zo"
      },
      "outputs": [],
      "source": [
        "import multiprocessing as mp\n",
        "import os\n",
        "\n",
        "num_processes = mp.cpu_count()\n",
        "pool = mp.Pool(num_processes)\n",
        "\n",
        "out_dir = \"spectrograms/transformed-v3/ambient/\"\n",
        "in_dir = \"spectrograms/ambient/\"\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    if not os.path.exists(out_dir):\n",
        "        os.makedirs(out_dir)\n",
        "\n",
        "    files = os.listdir(in_dir)\n",
        "\n",
        "    # Create a pool of processes\n",
        "    num_processes = mp.cpu_count()\n",
        "    pool = mp.Pool(num_processes)\n",
        "\n",
        "    # Use the pool to process the files\n",
        "    results = []\n",
        "    for f in files:\n",
        "        result = pool.apply_async(pre_process_img_v3, args=(in_dir + f, out_dir + f))\n",
        "        results.append(result)\n",
        "\n",
        "    # Wait for all processes to complete\n",
        "    for result in results:\n",
        "        result.wait()\n",
        "\n",
        "    # Close the pool to free up resources\n",
        "    pool.close()\n",
        "    pool.join()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d31uerlRQO2j",
        "outputId": "7a3102b3-a1b5-40a1-fa94-c4b0f8719c35"
      },
      "outputs": [],
      "source": [
        "print(len(os.listdir('/content/spectrograms/transformed-v3/ambient')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0RJxdttfAQ1",
        "outputId": "ea8a800c-8a23-45e7-9b5b-beb9833e1f88"
      },
      "outputs": [],
      "source": [
        "# cnn model v3 even lightweight\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adagrad\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (180, 180, 1)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    Conv2D(4, kernel_size=(2, 2), activation=Activation('swish'), input_shape=input_shape),\n",
        "    Flatten(),\n",
        "    Dense(2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model with binary cross-entropy loss and Adagrad optimizer\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adagrad(), metrics=['accuracy'])\n",
        "\n",
        "# Define the data generator\n",
        "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load the training data from the directory\n",
        "train_data = data_generator.flow_from_directory(\n",
        "    'spectrograms/transformed-v3/',\n",
        "    target_size=(180,180),\n",
        "    batch_size=256,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# print(train_data)\n",
        "\n",
        "# Train the model for 3 epochs\n",
        "model.fit(train_data, epochs=3)\n",
        "\n",
        "# Convert the model to TensorFlow Lite format with float16 quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "quantized_model = converter.convert()\n",
        "\n",
        "# Save the quantized model\n",
        "with open('cnn_model_v2.tflite', 'wb') as f:\n",
        "    f.write(quantized_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LafA9BM_CyNZ",
        "outputId": "0e195675-b99a-416f-fd76-e60fe1bed5f1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# from PIL import Image\n",
        "\n",
        "def predict_with_tflite(image_path, model_path):\n",
        "\n",
        "    image = pre_process_img_v3(image_path,'')\n",
        "\n",
        "    image = image / 255.0\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    image = image.astype(np.float32)\n",
        "\n",
        "    # print(image.shape)\n",
        "\n",
        "    # Load the model\n",
        "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Get the input and output tensors\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    # Make the prediction\n",
        "    interpreter.set_tensor(input_details[0]['index'], image)\n",
        "    interpreter.invoke()\n",
        "    prediction = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "    # Return the prediction\n",
        "    return prediction[0]\n",
        "\n",
        "\n",
        "prediction = predict_with_tflite('spectrograms/sawing/file7810.png', 'cnn_model_v2.tflite')\n",
        "prediction_dic = {0:'ambient',1:'sawing'}\n",
        "print(prediction_dic[np.argmax(prediction)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2joA85JZZdnD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
